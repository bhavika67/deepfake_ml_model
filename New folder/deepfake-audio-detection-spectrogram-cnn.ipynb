{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:58:23.154315Z",
     "iopub.status.busy": "2024-12-07T21:58:23.153886Z",
     "iopub.status.idle": "2024-12-07T21:58:36.766948Z",
     "shell.execute_reply": "2024-12-07T21:58:36.766283Z",
     "shell.execute_reply.started": "2024-12-07T21:58:23.154285Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "import keras\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "import random\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import BatchNormalization, Conv2D, Dense, Dropout, Flatten, MaxPool2D, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:58:36.768746Z",
     "iopub.status.busy": "2024-12-07T21:58:36.768335Z",
     "iopub.status.idle": "2024-12-07T21:58:36.773452Z",
     "shell.execute_reply": "2024-12-07T21:58:36.772343Z",
     "shell.execute_reply.started": "2024-12-07T21:58:36.76872Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Using the standardized 2-second truncated audio files\n",
    "\n",
    "train_real_directory = \"/kaggle/input/the-fake-or-real-dataset/for-2sec/for-2seconds/training/real\"\n",
    "train_fake_directory = \"/kaggle/input/the-fake-or-real-dataset/for-2sec/for-2seconds/training/fake\"\n",
    "\n",
    "validation_real_directory = \"/kaggle/input/the-fake-or-real-dataset/for-2sec/for-2seconds/validation/real\"\n",
    "validation_fake_directory = \"/kaggle/input/the-fake-or-real-dataset/for-2sec/for-2seconds/validation/fake\"\n",
    "\n",
    "test_real_directory = \"/kaggle/input/the-fake-or-real-dataset/for-2sec/for-2seconds/testing/real\"\n",
    "test_fake_directory = \"/kaggle/input/the-fake-or-real-dataset/for-2sec/for-2seconds/testing/fake\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:58:36.774988Z",
     "iopub.status.busy": "2024-12-07T21:58:36.774622Z",
     "iopub.status.idle": "2024-12-07T21:58:37.622431Z",
     "shell.execute_reply": "2024-12-07T21:58:37.621471Z",
     "shell.execute_reply.started": "2024-12-07T21:58:36.774947Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Get waveform (.wav) audio files\n",
    "\n",
    "train_real_audio = [os.path.join(train_real_directory, file) for file in os.listdir(train_real_directory) if file.endswith('.wav')]\n",
    "train_fake_audio = [os.path.join(train_fake_directory, file) for file in os.listdir(train_fake_directory) if file.endswith('.wav')]\n",
    "\n",
    "validation_real_audio = [os.path.join(validation_real_directory, file) for file in os.listdir(validation_real_directory) if file.endswith('.wav')]\n",
    "validation_fake_audio = [os.path.join(validation_fake_directory, file) for file in os.listdir(validation_fake_directory) if file.endswith('.wav')]\n",
    "\n",
    "test_real_audio = [os.path.join(test_real_directory, file) for file in os.listdir(test_real_directory) if file.endswith('.wav')]\n",
    "test_fake_audio = [os.path.join(test_fake_directory, file) for file in os.listdir(test_fake_directory) if file.endswith('.wav')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:58:37.623815Z",
     "iopub.status.busy": "2024-12-07T21:58:37.623541Z",
     "iopub.status.idle": "2024-12-07T21:58:37.647469Z",
     "shell.execute_reply": "2024-12-07T21:58:37.646631Z",
     "shell.execute_reply.started": "2024-12-07T21:58:37.623772Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Taking a random audio file\n",
    "random_audio_file = train_real_audio[random.randint(0, 6977)]\n",
    "ipd.Audio(random_audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:58:37.649586Z",
     "iopub.status.busy": "2024-12-07T21:58:37.649342Z",
     "iopub.status.idle": "2024-12-07T21:58:50.43985Z",
     "shell.execute_reply": "2024-12-07T21:58:50.438926Z",
     "shell.execute_reply.started": "2024-12-07T21:58:37.649563Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Visualize waveform of sample audio above\n",
    "# sr (sample rate) refers to the frequency of \"snapshots\" of the audio used for digital representation\n",
    "audio_data, sample_rate = librosa.load(random_audio_file)\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.waveshow(audio_data, sr=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:58:50.441432Z",
     "iopub.status.busy": "2024-12-07T21:58:50.440919Z",
     "iopub.status.idle": "2024-12-07T21:58:50.446525Z",
     "shell.execute_reply": "2024-12-07T21:58:50.445584Z",
     "shell.execute_reply.started": "2024-12-07T21:58:50.441404Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Convert audio file to spectrogram\n",
    "# def create_spectrogram(file_path):\n",
    "#     audio_data, sample_rate = librosa.load(file_path)\n",
    "#     spectrogram = librosa.stft(audio_data)\n",
    "#     decibel_spectrogram = librosa.amplitude_to_db(abs(spectrogram))\n",
    "#     return decibel_spectrogram\n",
    "\n",
    "# Convert audio file to mel-scale spectrogram\n",
    "# See https://medium.com/analytics-vidhya/understanding-the-mel-spectrogram-fca2afa2ce53\n",
    "def create_mel_spectrogram(file_path):\n",
    "    audio_data, sample_rate = librosa.load(file_path)  \n",
    "    # Convert audio to mel-based spectrogram\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
    "    # Convert from amplitude squared to decibel units\n",
    "    mel_decibel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)  \n",
    "    return mel_decibel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:58:50.447897Z",
     "iopub.status.busy": "2024-12-07T21:58:50.44754Z",
     "iopub.status.idle": "2024-12-07T21:58:52.14755Z",
     "shell.execute_reply": "2024-12-07T21:58:52.146625Z",
     "shell.execute_reply.started": "2024-12-07T21:58:50.447859Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Spectrogram representation of the sample wave form above\n",
    "sample_spectrogram = create_mel_spectrogram(random_audio_file)\n",
    "plt.figure(figsize=(15, 5))\n",
    "librosa.display.specshow(sample_spectrogram, x_axis='time', y_axis='hz')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T21:58:52.149105Z",
     "iopub.status.busy": "2024-12-07T21:58:52.148643Z",
     "iopub.status.idle": "2024-12-07T22:05:29.544456Z",
     "shell.execute_reply": "2024-12-07T22:05:29.543231Z",
     "shell.execute_reply.started": "2024-12-07T21:58:52.149077Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Use spectrograms as features to train the model\n",
    "def get_features_and_labels(real_audio_files, fake_audio_files):\n",
    "    spec_arr = []\n",
    "    labels = []\n",
    "    \n",
    "    for file in real_audio_files:\n",
    "        spectrogram = create_mel_spectrogram(file)\n",
    "        spec_arr.append(spectrogram)\n",
    "        labels.append(0)\n",
    "    for file in fake_audio_files:\n",
    "        spectrogram = create_mel_spectrogram(file)\n",
    "        spec_arr.append(spectrogram)\n",
    "        labels.append(1)\n",
    "    \n",
    "    return np.array(spec_arr), np.array(labels)\n",
    "\n",
    "train_features, train_labels = get_features_and_labels(train_real_audio, train_fake_audio)\n",
    "validation_features, validation_labels = get_features_and_labels(validation_real_audio, validation_fake_audio)\n",
    "test_features, test_labels = get_features_and_labels(test_real_audio, test_fake_audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T22:05:29.555708Z",
     "iopub.status.busy": "2024-12-07T22:05:29.555251Z",
     "iopub.status.idle": "2024-12-07T22:05:29.577746Z",
     "shell.execute_reply": "2024-12-07T22:05:29.575516Z",
     "shell.execute_reply.started": "2024-12-07T22:05:29.555656Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"train features shape: {}\".format(train_features.shape))\n",
    "print(\"test features shape: {}\".format(test_features.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T22:05:29.580243Z",
     "iopub.status.busy": "2024-12-07T22:05:29.579822Z",
     "iopub.status.idle": "2024-12-07T22:05:30.567149Z",
     "shell.execute_reply": "2024-12-07T22:05:30.566408Z",
     "shell.execute_reply.started": "2024-12-07T22:05:29.580194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Significantly trimmed VGG model to optimize results\n",
    "\n",
    "trimmed_vgg = Sequential()\n",
    "trimmed_vgg.add(Reshape((128, 87, 1),input_shape=train_features.shape[1:]))\n",
    "\n",
    "trimmed_vgg.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation='relu'))\n",
    "trimmed_vgg.add(Conv2D(filters=64, kernel_size=(3,3), padding=\"same\", activation='relu'))\n",
    "trimmed_vgg.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "trimmed_vgg.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation='relu'))\n",
    "trimmed_vgg.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation='relu'))\n",
    "trimmed_vgg.add(MaxPool2D(pool_size=(2,2), strides=(2,2)))\n",
    "\n",
    "trimmed_vgg.add(Flatten())\n",
    "trimmed_vgg.add(Dense(units=256,activation=\"relu\"))\n",
    "trimmed_vgg.add(Dense(units=256,activation=\"relu\"))\n",
    "trimmed_vgg.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "trimmed_vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T22:05:30.568874Z",
     "iopub.status.busy": "2024-12-07T22:05:30.568515Z",
     "iopub.status.idle": "2024-12-07T22:05:30.582826Z",
     "shell.execute_reply": "2024-12-07T22:05:30.581906Z",
     "shell.execute_reply.started": "2024-12-07T22:05:30.568836Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Compile model\n",
    "# Adam optimiser helps model get unstuck when stuck at local minima\n",
    "trimmed_vgg.compile(optimizer=keras.optimizers.Adam(),\n",
    "                    loss=keras.losses.binary_crossentropy, \n",
    "                    metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T22:05:30.584162Z",
     "iopub.status.busy": "2024-12-07T22:05:30.583887Z",
     "iopub.status.idle": "2024-12-07T22:07:45.931677Z",
     "shell.execute_reply": "2024-12-07T22:07:45.93088Z",
     "shell.execute_reply.started": "2024-12-07T22:05:30.584114Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "trimmed_vgg_history = trimmed_vgg.fit(train_features,\n",
    "                                      train_labels,\n",
    "                                      validation_data = [validation_features, validation_labels],\n",
    "                                      batch_size = 32,\n",
    "                                      epochs = 10,\n",
    "                                      steps_per_epoch = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T22:07:45.935703Z",
     "iopub.status.busy": "2024-12-07T22:07:45.935414Z",
     "iopub.status.idle": "2024-12-07T22:07:46.369176Z",
     "shell.execute_reply": "2024-12-07T22:07:46.368386Z",
     "shell.execute_reply.started": "2024-12-07T22:07:45.935676Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 7))\n",
    "\n",
    "ax1.plot(trimmed_vgg_history.history[\"accuracy\"])\n",
    "ax1.plot(trimmed_vgg_history.history['val_accuracy'])\n",
    "ax1.set_title(\"Accuracy\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.legend([\"Accuracy\",\"Validation Accuracy\"])\n",
    "\n",
    "ax2.plot(trimmed_vgg_history.history[\"loss\"])\n",
    "ax2.plot(trimmed_vgg_history.history[\"val_loss\"])\n",
    "ax2.set_title(\"Loss\")\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.legend([\"Loss\",\"Validation Loss\"])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T22:07:46.370793Z",
     "iopub.status.busy": "2024-12-07T22:07:46.370435Z",
     "iopub.status.idle": "2024-12-07T22:07:46.966878Z",
     "shell.execute_reply": "2024-12-07T22:07:46.96617Z",
     "shell.execute_reply.started": "2024-12-07T22:07:46.370755Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Test Data Results\n",
    "\n",
    "trimmed_vgg_loss, trimmed_vgg_accuracy = trimmed_vgg.evaluate(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-07T22:07:46.968309Z",
     "iopub.status.busy": "2024-12-07T22:07:46.968033Z",
     "iopub.status.idle": "2024-12-07T22:07:47.344494Z",
     "shell.execute_reply": "2024-12-07T22:07:47.343698Z",
     "shell.execute_reply.started": "2024-12-07T22:07:46.968282Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Saving the final version\n",
    "\n",
    "trimmed_vgg.save('deepfake_audio_detector.h5')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 4555568,
     "sourceId": 8130934,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
